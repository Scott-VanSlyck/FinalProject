title: "ST 558: Final Project (Modeling)"
authors: "Scott Van Slyck"
description: "Modeling File for Final Project"
date: "July 29, 2024"
format: html
editor: visual
---

Loading/Installing packages necessary
```{r}
#| echo: FALSE

packages <- c("tidyverse", "caret", "glmnet")

install_if_missing <- function(package) {
  if (!require(package, character.only = TRUE)) {
    install.packages(package, dependencies = TRUE)
    library(package, character.only = TRUE)
  }
}

lapply(packages, install_if_missing)
```

## Introduction

In this project, we are working with a dataset from the Diabetes Health Indicators to predict the diabetes status of individuals. The response variable, `Diabetes_binary`, indicates whether or not a patient has diabetes.  Our goal is to create predictive models for the `Diabetes_binary` variable using various machine learning techniques. We will evaluate the models using log loss as our primary metric.

First we will start by reading in the data and splitting it into training and testing sets.
```{r}
# Reading in the data using a relative path and manipulating it

# reading in the csv file
DBH <- read_csv("diabetes_binary_health_indicators_BRFSS2015.csv")

# selecting the variables I want
DBH <- DBH[, c(1,2,5,6,9,11,19,20,22)]

# Changing the possible factor variables into factors
DBH$HighBP <- factor(DBH$HighBP, levels = c(0, 1), labels = c("Not_High", "High"))
DBH$Smoker <- factor(DBH$Smoker, levels = c(0, 1), labels = c("No", "Yes"))
DBH$PhysActivity <- factor(DBH$PhysActivity, levels = c(0, 1), labels = c("No", "Yes"))
DBH$Veggies <- factor(DBH$Veggies, levels = c(0, 1), labels = c("No", "Yes"))
DBH$Sex <- factor(DBH$Sex, levels = c(0, 1), labels = c("Female", "Male"))
DBH$Age <- factor(DBH$Age, 
                  levels = 1:13, 
                  labels = c("18_24", "25_29", "30_34", "35_39", "40_44", "45_49", 
                             "50_54", "55_59", "60_64", "65_69", "70_74", "75_79", "80_plus"))
DBH$Income <- factor(DBH$Income, 
                     levels = 1:8, 
                     labels = c("Less_than_10k", "10k_to_15k", "15k_to_20k", 
                                "20k_to_25k", "25k_to_35k", "35k_to_50k", 
                                "50k_to_75k", "75k_or_more"))
DBH$Diabetes_binary <- factor(DBH$Diabetes_binary, levels = c(0, 1), labels = c("No_Diabetes", "Diabetes"))

# Setting seed and splitting data into training and test sets
set.seed(270)

trainIndex <- createDataPartition(DBH$Diabetes_binary, p = 0.7, list = FALSE)

trainData <- DBH[trainIndex, ]
testData <- DBH[-trainIndex, ]
```

Log loss, also known as logistic loss or cross-entropy loss, is a measure of how well a model's predicted probabilities match the actual outcomes. It evaluates how accurate and confident a model is about it's prediction, it penalizes wrong predictions with high confidence more than one that is unsure. These penalties result in the model taking more precise and cautious estimates. Where it differs from accuracy is it provides a more detailed view of performance when considering confidence of predictions. This is useful in scenarios where predicting the majority class can give misleadingly high accuracy, focusing on probability estimates allows log loss to help create more reliable models for real-world applications where knowing the likelihood of an outcome is of utmost importance.


## Logistic Regression Models
First we will start our modeling with looking at logistic regression models. Logistic regression is a statistical method of modeling to display relationships between a binary response variable and independent variables. Logistic regression's binary outcome results in the prediction of the probability of the outcome which can be useful for risk assessment. They are easily interpretable due to the coefficients being displayed as log odds of the outcome making it easy to understand the impact of each predictor.

```{r}
# Control for cross evalution with 3-folds

train_control <- trainControl(method = "cv", number = 3, classProbs = TRUE, summaryFunction = mnLogLoss)

# Re-set seed
set.seed(270)

# Model 1: Basic Logistic Regression
log_model1 <- train(Diabetes_binary ~ ., data = trainData, method = "glm", family = "binomial", 
                    trControl = train_control, metric = "logLoss")

# Model 2: Logistic Regression with selected predictors
selected_predictors2 <- c("HighBP", "BMI", "Smoker", "PhysActivity")
formula2 <- as.formula(paste("Diabetes_binary ~", paste(selected_predictors2, collapse = " + ")))

log_model2 <- train(formula2, data = trainData, method = "glm", family = "binomial", 
                    trControl = train_control, metric = "logLoss")

# Model 3: Logistic Regression with another set of selected predictors
selected_predictors3 <- c("Veggies", "Sex", "Age", "Income")
formula3 <- as.formula(paste("Diabetes_binary ~", paste(selected_predictors3, collapse = " + ")))

log_model3 <- train(formula3, data = trainData, method = "glm", family = "binomial", 
                    trControl = train_control, metric = "logLoss")

# Compare models
resamples_log <- resamples(list(Full = log_model1, Reduced1 = log_model2, Reduced2 = log_model3))
summary(resamples_log)
```

## Classification Tree
A classification tree is a supervised machine learning algorithm used to classify data into certain classes. The classification tree works by splitting the data set into subsets based on the value of a feature which create branches for each possible value. It is particularly useful in this scenario because our response value is a classified variable with either no diabetes or diabetes. This allows the algorithm to select the right features and split on the right values to classify whether or not a patient has diabetes.

```{r}
set.seed(270)

tree_model <- train(Diabetes_binary ~ ., data = trainData, method = "rpart", 
                    trControl = train_control, metric = "logLoss", tuneLength = 10)

# Print tree model
print(tree_model)
```

## Random Forest
A random forest is a robust machine learning model that is an improved version of a decision tree in comparison to individual ones. It combines multiple trees, averages them out, and takes randomness for it's selection of features. This allows for higher accuracy and less bias. It is valuable for both classification and regression learning. The downside is that it is computationally intensive, for the code below I have had to limit the trees it produces to 100 and reduce the 5-fold cross validation to 3-fold CV since the prior was taking more than an hour to run.


```{r}
set.seed(270)

rf_grid <- expand.grid(mtry = seq(2, ncol(trainData)-1, by = 2))

rf_model <- train(Diabetes_binary ~ ., data = trainData, method = "rf", 
                  trControl = train_control, metric = "logLoss", tuneGrid = rf_grid, ntree = 100)

# Print random forest model
print(rf_model)
```

## Final Model Selection
```{r}
# Ensure testData$Diabetes_binary has the same levels as trainData$Diabetes_binary
testData$Diabetes_binary <- factor(testData$Diabetes_binary, levels = levels(trainData$Diabetes_binary))

# Helper function to calculate mnLogLoss with debugging output
calculate_log_loss <- function(preds, actual) {
  data <- data.frame(obs = actual, preds)
  print(head(data))  # Print the head of the data frame for debugging
  print(table(data$obs))  # Print a table of the observed values for debugging
  mnLogLoss(data, lev = levels(actual))
}

# Predict on the test set using the best logistic regression model
log_preds1 <- predict(log_model1, newdata = testData, type = "prob")
print(head(log_preds1))  # Print the head of the predicted probabilities for debugging
log_loss_test1 <- calculate_log_loss(log_preds1, testData$Diabetes_binary)

log_preds2 <- predict(log_model2, newdata = testData, type = "prob")
print(head(log_preds2))  # Print the head of the predicted probabilities for debugging
log_loss_test2 <- calculate_log_loss(log_preds2, testData$Diabetes_binary)

log_preds3 <- predict(log_model3, newdata = testData, type = "prob")
print(head(log_preds3))  # Print the head of the predicted probabilities for debugging
log_loss_test3 <- calculate_log_loss(log_preds3, testData$Diabetes_binary)

# Print the log loss values
print(c(log_loss_test1, log_loss_test2, log_loss_test3))

# Predict on the test set using the classification tree model
tree_preds <- predict(tree_model, newdata = testData, type = "prob")
print(head(tree_preds))  # Print the head of the predicted probabilities for debugging
tree_loss_test <- calculate_log_loss(tree_preds, testData$Diabetes_binary)
print(tree_loss_test)

# Predict on the test set using the random forest model
rf_preds <- predict(rf_model, newdata = testData, type = "prob")
print(head(rf_preds))  # Print the head of the predicted probabilities for debugging
rf_loss_test <- calculate_log_loss(rf_preds, testData$Diabetes_binary)
print(rf_loss_test)

# Compare the log loss of all models
model_comparison <- data.frame(
  Model = c("Full Logistic Regression", "Reduced Model 1", "Reduced Model 2", "Classification Tree", "Random Forest"),
  LogLoss = c(log_loss_test1, log_loss_test2, log_loss_test3, tree_loss_test, rf_loss_test)
)
print(model_comparison)
```

The best model, selected by which final model had the lowest logLoss was the full logistic regression model.
